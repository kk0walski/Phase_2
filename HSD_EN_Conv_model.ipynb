{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hate Speech Detector - EN - Convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "from klepto.archives import dir_archive\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, AvgPool2D, Flatten, Concatenate\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow import split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = dir_archive('hsd/Reddit/X_y_conv', {}, cached=True)\n",
    "archive.load()\n",
    "\n",
    "features = archive['features']\n",
    "labels = archive['labels']\n",
    "first_card = archive['wt_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55132, 12, 300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh = features.shape\n",
    "sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55132, 12, 100, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features =  features.reshape(sh[0], sh[1], int(sh[2]/3), 3)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model was selected using a GridSearch with 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "LAYERS = 3  # convolutional layers count\n",
    "LR = 0.001  # learning rate\n",
    "OPTIM = tf.keras.optimizers.Adam  # optimizer\n",
    "EPOCHS = 20\n",
    "\n",
    "# params\n",
    "BATCH_SIZE = 100  # size of input batch\n",
    "INIT = 'random_normal'  # trainable param initializer\n",
    "CONV_FILTER = (2, 4)  # convolution filter\n",
    "POOL_FILTER = (2, 4)  # pooling filter\n",
    "POOL_STRIDE = (2, 4)  # pooling stride\n",
    "\n",
    "#non-testing params\n",
    "CHANNELS = 64  # convolutional layer channels\n",
    "POOL = MaxPool2D  # pooling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_RATIO = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train x: 38592\n",
      "Train y: 38592\n",
      "Test x: 16540\n",
      "Test y: 16540\n"
     ]
    }
   ],
   "source": [
    "X_train = features[:int(SPLIT_RATIO*len(features))]\n",
    "y_train = labels[:int(SPLIT_RATIO*len(labels))]\n",
    "X_test = features[int(SPLIT_RATIO*len(features)):]\n",
    "y_test = labels[int(SPLIT_RATIO*len(labels)):]\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print('Train x: {}'.format(len(X_train)))\n",
    "print('Train y: {}'.format(len(y_train)))\n",
    "print('Test x: {}'.format(len(X_test)))\n",
    "print('Test y: {}'.format(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super(MetricsCallback, self).__init__()\n",
    "        self.val_f1s0 = []\n",
    "        self.val_f1s1 = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = np.asarray(tf.argmax(self.model.predict(X_test), axis=1))\n",
    "        val_true = np.asarray(tf.argmax(y_test, axis=1))\n",
    "        c_m = confusion_matrix(val_true, val_predict, labels=[0, 1])\n",
    "        self.val_f1s0.append(2*float(c_m[0][0])/(2*float(c_m[0][0]) + c_m[0][1] + c_m[1][0]))\n",
    "        self.val_f1s1.append(2*float(c_m[1][1])/(2*float(c_m[1][1]) + c_m[1][0] + c_m[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel():\n",
    "    def __init__(self, wt_card, input_shape, name='conv_model', **kwargs):\n",
    "        self.wt_card = wt_card\n",
    "        \n",
    "        # hyperparams\n",
    "        self.layers = LAYERS if 'layers' not in kwargs else kwargs['layers']\n",
    "        self.lr = LR if 'lr' not in kwargs else kwargs['lr']\n",
    "        self.optim = OPTIM(learning_rate=self.lr) if 'optim' not in kwargs else kwargs['optim'](learning_rate=self.lr)\n",
    "        self.epochs = EPOCHS if 'epochs' not in kwargs else kwargs['epochs']\n",
    "        \n",
    "        # params\n",
    "        self.batch_size = BATCH_SIZE if 'batch_size' not in kwargs else kwargs['batch_size']\n",
    "        self.init = INIT if 'init' not in kwargs else kwargs['init']\n",
    "        self.channels = CHANNELS if 'channels' not in kwargs else kwargs['channels']\n",
    "        self.conv_filter = CONV_FILTER if 'conv_filter' not in kwargs else kwargs['conv_filter']\n",
    "        self.pool_filter = POOL_FILTER if 'pool_filter' not in kwargs else kwargs['pool_filter']\n",
    "        self.pool_stride = POOL_STRIDE if 'pool_stride' not in kwargs else kwargs['pool_stride']\n",
    "        self.pool = POOL if 'pool' not in kwargs else kwargs['pool']\n",
    "        \n",
    "        # layers\n",
    "        inputs = Input(shape=input_shape, name='features')\n",
    "        # wt_inputs, pos_inputs = Lambda(lambda x: split(x, [self.wt_card, x.shape[1] - self.wt_card], axis=1), name='wt_pos_split')(inputs)\n",
    "        \n",
    "        x1 = Conv2D(self.channels, kernel_size = self.conv_filter,\n",
    "                    activation='relu', name='wt_conv_1',\n",
    "                    kernel_initializer = self.init, bias_initializer = self.init)(inputs)\n",
    "        # x2 = Conv2D(self.channels, kernel_size = self.conv_filter,\n",
    "        #             activation='relu', name='pos_conv_1',\n",
    "        #             kernel_initializer = self.init, bias_initializer = self.init)(pos_inputs)\n",
    "        for layer in range(self.layers)[1:]:\n",
    "            x1 = Conv2D(self.channels, kernel_size = self.conv_filter,\n",
    "                        activation='relu', name='wt_conv_{}'.format(layer+1),\n",
    "                        kernel_initializer = self.init, bias_initializer = self.init)(x1)\n",
    "            # x2 = Conv2D(self.channels, kernel_size = self.conv_filter,\n",
    "            #             activation='relu', name='pos_conv_{}'.format(layer+1),\n",
    "            #             kernel_initializer = self.init, bias_initializer = self.init)(x2)\n",
    "        \n",
    "        x1 = self.pool(pool_size=self.pool_filter, strides=self.pool_stride, name='wt_pool')(x1)\n",
    "        # x2 = self.pool(pool_size=self.pool_filter, strides=self.pool_stride, name='pos_pool')(x2)\n",
    "        \n",
    "        x = Flatten(name='wt_flatten')(x1)\n",
    "        # x2 = Flatten(name='pos_flatten')(x2)\n",
    "        \n",
    "        # x = Concatenate(axis=1, name='concatenation')([x1, x2])\n",
    "        \n",
    "        x = Dense(64, activation='relu', name='dense_1',\n",
    "                  kernel_initializer='random_normal', bias_initializer='random_normal')(x)\n",
    "        x = Dense(64, activation='relu', name='dense_2',\n",
    "                  kernel_initializer='random_normal', bias_initializer='random_normal')(x)\n",
    "        outputs = Dense(2, activation='softmax', name='predictions',\n",
    "                        kernel_initializer='random_normal', bias_initializer='random_normal')(x)\n",
    "        \n",
    "        self.name = name\n",
    "        self.model = Model(inputs=inputs, outputs=outputs, name=name)\n",
    "        self.mc = MetricsCallback()\n",
    "    \n",
    "    def summary(self):\n",
    "        return self.model.summary()\n",
    "    \n",
    "    def compile(self):\n",
    "        self.model.compile(optimizer=self.optim,\n",
    "                           loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                           metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    def fit(self, X_tr, y_tr, X_ev, y_ev):\n",
    "        return self.model.fit(X_tr, y_tr, batch_size=self.batch_size, epochs=self.epochs,\n",
    "                              validation_data=(X_ev, y_ev), callbacks=[self.mc])\n",
    "    \n",
    "    def predict(self, X_t):\n",
    "        return self.model.predict(X_t)\n",
    "    \n",
    "    def save(self, file_name):\n",
    "        self.model.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_comparison_bars(df, title, interval=2, save_file=None):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(16, 4))\n",
    "    \n",
    "    labels = [i+1 if i%interval == 0 else '' for i in range(len(df))]\n",
    "    x = range(len(labels))\n",
    "    acc = df['acc'].values\n",
    "    f1s0 = df['f1s0'].values\n",
    "    f1s1 = df['f1s1'].values\n",
    "    \n",
    "    max_acc_id = np.argmax(acc)\n",
    "    max_f1s0_id = np.argmax(f1s0)\n",
    "    max_f1s1_id = np.argmax(f1s1)\n",
    "    \n",
    "    axs[0].bar(x, acc, color='r')\n",
    "    axs[0].set_xlabel('Model number')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xticks(x)\n",
    "    axs[0].set_xticklabels(labels)\n",
    "    axs[0].set_ylim([0, 1])\n",
    "    axs[0].set_title('Accuracy | max ({}) at: {}'.format(np.round(np.max(acc), 2), max_acc_id+1))\n",
    "    axs[0].patches[max_acc_id].set_facecolor('g')\n",
    "    \n",
    "    axs[1].bar(x, f1s0, color='b')\n",
    "    axs[1].set_xlabel('Model number')\n",
    "    axs[1].set_ylabel('F1 score (no hate)')\n",
    "    axs[1].set_title('F1 score (no hate) | max ({}) at: {}'.format(np.round(np.max(f1s0), 2), max_f1s0_id+1))\n",
    "    axs[1].set_xticks(x)\n",
    "    axs[1].set_xticklabels(labels)\n",
    "    axs[1].set_ylim([0, 1])\n",
    "    axs[1].patches[max_f1s0_id].set_facecolor('g')\n",
    "    \n",
    "    axs[2].bar(x, f1s1, color='m')\n",
    "    axs[2].set_xlabel('Model number')\n",
    "    axs[2].set_ylabel('F1 score (hate speech)')\n",
    "    axs[2].set_title('F1 score (hate speech) | max ({}) at: {}'.format(np.round(np.max(f1s1), 2),\n",
    "                                                                       max_f1s1_id+1))\n",
    "    axs[2].set_xticks(x)\n",
    "    axs[2].set_xticklabels(labels)\n",
    "    axs[2].set_ylim([0, 1])\n",
    "    axs[2].patches[max_f1s1_id].set_facecolor('g')\n",
    "    \n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    if save_file:\n",
    "        plt.savefig(save_file)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model hyperparams researching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_options = [2, 3, 4]\n",
    "lr_options = [0.1, 0.01, 0.001]\n",
    "optim_options = [tf.keras.optimizers.Adam, tf.keras.optimizers.SGD]\n",
    "epochs_options = [5, 10, 15]\n",
    "\n",
    "hp_options = []\n",
    "for epochs in [epochs_options[-1]]:  # changed to process 15 epochs (eval. after each 5)\n",
    "    for lr in lr_options:\n",
    "        for optim in optim_options:\n",
    "            for layer in layers_options:\n",
    "                hp_options.append({'lr': lr, 'optim': optim, 'epochs': epochs, 'layers': layer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>optim</th>\n",
       "      <th>epochs</th>\n",
       "      <th>layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.a...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.g...</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>&lt;class 'tensorflow.python.keras.optimizer_v2.g...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lr                                              optim  epochs  layers\n",
       "0  0.1  <class 'tensorflow.python.keras.optimizer_v2.a...      15       2\n",
       "1  0.1  <class 'tensorflow.python.keras.optimizer_v2.a...      15       3\n",
       "2  0.1  <class 'tensorflow.python.keras.optimizer_v2.a...      15       4\n",
       "3  0.1  <class 'tensorflow.python.keras.optimizer_v2.g...      15       2\n",
       "4  0.1  <class 'tensorflow.python.keras.optimizer_v2.g...      15       3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(hp_options).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Researching for 1/18 | Hyperparams: {'lr': 0.1, 'optim': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'epochs': 15, 'layers': 2}\n",
      "\n",
      "Epoch 1/15\n",
      "386/386 [==============================] - 75s 192ms/step - loss: 6.3500 - categorical_accuracy: 0.8200 - val_loss: 0.3828 - val_categorical_accuracy: 0.8720\n",
      "Epoch 2/15\n",
      "386/386 [==============================] - 84s 219ms/step - loss: 0.4328 - categorical_accuracy: 0.8448 - val_loss: 0.3829 - val_categorical_accuracy: 0.8720\n",
      "Epoch 3/15\n",
      "386/386 [==============================] - 84s 216ms/step - loss: 0.4312 - categorical_accuracy: 0.8455 - val_loss: 0.3992 - val_categorical_accuracy: 0.8720\n",
      "Epoch 4/15\n",
      "386/386 [==============================] - 94s 243ms/step - loss: 0.4309 - categorical_accuracy: 0.8461 - val_loss: 0.3847 - val_categorical_accuracy: 0.8720\n",
      "Epoch 5/15\n",
      "386/386 [==============================] - 94s 244ms/step - loss: 0.4288 - categorical_accuracy: 0.8470 - val_loss: 0.3827 - val_categorical_accuracy: 0.8720\n",
      "Epoch 6/15\n",
      "386/386 [==============================] - 95s 247ms/step - loss: 0.4326 - categorical_accuracy: 0.8450 - val_loss: 0.3888 - val_categorical_accuracy: 0.8720\n",
      "Epoch 7/15\n",
      "386/386 [==============================] - 96s 250ms/step - loss: 0.4293 - categorical_accuracy: 0.8468 - val_loss: 0.3826 - val_categorical_accuracy: 0.8720\n",
      "Epoch 8/15\n",
      "386/386 [==============================] - 96s 250ms/step - loss: 0.4313 - categorical_accuracy: 0.8460 - val_loss: 0.3837 - val_categorical_accuracy: 0.8720\n",
      "Epoch 9/15\n",
      "204/386 [==============>...............] - ETA: 42s - loss: 0.4438 - categorical_accuracy: 0.8394"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('results/en_conv/hyperparams_research.csv'):\n",
    "    hp_results = []\n",
    "    for i, opts in enumerate(hp_options):\n",
    "        print('\\nResearching for {}/{} | Hyperparams: {}\\n'.format(i+1, len(hp_options), opts))\n",
    "\n",
    "        hp_model = ConvModel(wt_card=first_card, input_shape=(12, 100, 3, ), **opts)\n",
    "        hp_model.compile()\n",
    "        hp_history = hp_model.fit(X_train, y_train, X_test, y_test)\n",
    "\n",
    "        # append means for 5, 10 and 15 epochs\n",
    "        for eps in epochs_options:\n",
    "            hp_results.append({'acc': np.mean(hp_history.history['categorical_accuracy'][:eps]),\n",
    "                               'val_acc': np.mean(hp_history.history['val_categorical_accuracy'][:eps]),\n",
    "                               'loss': np.mean(hp_history.history['val_loss'][:eps]),\n",
    "                               'f1s0': np.mean(hp_model.mc.val_f1s0[:eps]),\n",
    "                               'f1s1': np.mean(hp_model.mc.val_f1s1[:eps])})\n",
    "    \n",
    "    hp_results_df = pd.DataFrame(hp_results)\n",
    "    hp_results_df.to_csv('results/en_conv/hyperparams_research.csv')\n",
    "else:\n",
    "    hp_results_df = pd.read_csv('results/en_conv/hyperparams_research.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_comparison_bars(hp_results_df, title='Hyperparams research', interval=10,\n",
    "                       save_file='results/en_conv/hyperparams_research.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_h_num = 42\n",
    "'Best one: {} with {} run epochs'.format(hp_options[int((best_h_num-1)/3)],\n",
    "                                         ((best_h_num-1)%3)*5 if (best_h_num-1)%3 != 0 else 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model params researching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_options = [100, 200]\n",
    "init_options = ['random_uniform', 'random_normal']\n",
    "conv_filter_options = [(1, 2), (2, 4)]\n",
    "pool_filter_options = [(1, 2), (2, 4)]\n",
    "pool_stride_options = [(1, 2), (2, 4)]\n",
    "\n",
    "p_options = []\n",
    "for batch_size in batch_size_options:\n",
    "    for init in init_options:\n",
    "        for conv_filter in conv_filter_options:\n",
    "            for pool_filter in pool_filter_options:\n",
    "                for pool_stride in pool_stride_options:\n",
    "                    p_options.append({'batch_size': batch_size,\n",
    "                                      'init': init,\n",
    "                                      'conv_filter': conv_filter,\n",
    "                                      'pool_filter': pool_filter,\n",
    "                                      'pool_stride': pool_stride})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(p_options).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('results/en_conv/params_research.csv'):\n",
    "    p_results = []\n",
    "    for i, opts in enumerate(p_options):\n",
    "        print('\\nResearching for {}/{} | Params: {}\\n'.format(i+1, len(p_options), opts))\n",
    "\n",
    "        p_model = ConvModel(wt_card=first_card, input_shape=(25, 40, 3), **opts)\n",
    "        p_model.compile()\n",
    "        p_history = p_model.fit(X_train, y_train, X_test, y_test)\n",
    "\n",
    "        p_results.append({'acc': np.mean(p_history.history['categorical_accuracy']),\n",
    "                          'val_acc': np.mean(p_history.history['val_categorical_accuracy']),\n",
    "                          'loss': np.mean(p_history.history['val_loss']),\n",
    "                          'f1s0': np.mean(p_model.mc.val_f1s0),\n",
    "                          'f1s1': np.mean(p_model.mc.val_f1s1)})\n",
    "    \n",
    "    p_results_df = pd.DataFrame(p_results)\n",
    "    p_results_df.to_csv('results/en_conv/params_research.csv')\n",
    "else:\n",
    "    p_results_df = pd.read_csv('results/en_conv/params_research.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_comparison_bars(p_results_df, title='Params research', interval=5,\n",
    "                       save_file='results/en_conv/params_research.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_num = 16\n",
    "'Best one: {}'.format(p_options[best_num-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvModel(wt_card=first_card, input_shape=(16, 40, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile()\n",
    "history = model.fit(X_train, y_train, X_test, y_test)\n",
    "model.save('models/en_conv.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "y_true = tf.argmax(y_test, axis=1)\n",
    "y_pred = tf.argmax(predictions, axis=1)\n",
    "\n",
    "conf_mat = tf.math.confusion_matrix(labels=y_true, predictions=y_pred, num_classes=2).numpy()\n",
    "acc = float(np.sum(np.diag(conf_mat)))/np.sum(np.sum(conf_mat))\n",
    "f1s0 = 2*float(conf_mat[0][0])/(2*float(conf_mat[0][0]) + conf_mat[0][1] + conf_mat[1][0])\n",
    "f1s1 = 2*float(conf_mat[1][1])/(2*float(conf_mat[1][1]) + conf_mat[1][0] + conf_mat[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('results/en_conv/short_results.csv'):\n",
    "    with open('results/en_conv/short_results.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Accuracy', 'F1 score (0)', 'F1 score (1)'])\n",
    "        writer.writerow([acc, f1s0, f1s1])\n",
    "else:\n",
    "    with open('results/en_conv/short_results.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([acc, f1s0, f1s1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model history, confusion matrix and accuracy\n",
    "model_results = {'acc': history.history['categorical_accuracy'],\n",
    "                 'val_acc': history.history['val_categorical_accuracy'],\n",
    "                 'loss': history.history['loss'],\n",
    "                 'val_loss': history.history['val_loss'],\n",
    "                 'f1s0': model.mc.val_f1s0,\n",
    "                 'f1s1': model.mc.val_f1s1,\n",
    "                 'conf_mat': conf_mat,\n",
    "                 'main_acc': acc}\n",
    "with open('results/en_conv/results.pkl', 'wb') as f:\n",
    "    pickle.dump(model_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(y_ss, y_labels, colors, title, file_name=None):\n",
    "    x_s = range(1, len(y_ss[0])+1)\n",
    "    for y_s, y_label, color in zip(y_ss, y_labels, colors):\n",
    "        plt.plot(x_s, y_s, color, label=y_label)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Metrics')\n",
    "    tick_marks = np.arange(1, len(x_s) + 1)\n",
    "    plt.xticks(tick_marks, x_s)\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.legend(loc='best', frameon=False)\n",
    "    \n",
    "    if file_name:\n",
    "        plt.savefig(file_name)\n",
    "    plt.show()\n",
    "\n",
    "def twinx_plot(y11_s, y12_s, y21_s, y22_s, x_label, y1_label,y2_label, title,\n",
    "               styles=['r-', 'r--', 'b-', 'b--'], colors=['r', 'b'], file_name=None):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    ax1.set_xlabel(x_label)\n",
    "    ax1.set_xticks(range(1, len(y11_s)+1))\n",
    "    \n",
    "    ax1.set_ylabel(y1_label, color=colors[0])\n",
    "    ax1.plot(range(1, len(y11_s)+1), y11_s, styles[0], label='train acc.')\n",
    "    ax1.plot(range(1, len(y12_s)+1), y12_s, styles[1], label='valid. acc.')\n",
    "    ax1.tick_params(axis='y', labelcolor=colors[0])\n",
    "    \n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "    \n",
    "    ax2.set_ylabel(y2_label, color=colors[1])  # we already handled the x-label with ax1\n",
    "    ax2.plot(range(1, len(y21_s)+1), y21_s, styles[2], label='train loss')\n",
    "    ax2.plot(range(1, len(y22_s)+1), y22_s, styles[3], label='valid. loss')\n",
    "    ax2.tick_params(axis='y', labelcolor=colors[1])\n",
    "    \n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    fig.legend(loc='right', bbox_to_anchor=(0.85, 0.5))\n",
    "    plt.title(title)\n",
    "    \n",
    "    if file_name:\n",
    "        plt.savefig(file_name)\n",
    "    plt.show()\n",
    "\n",
    "def confusion_matrix_plot(conf_mat, cls, x_label, y_label, title, file_name=None):\n",
    "    plt.imshow(conf_mat, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel(x_label)\n",
    "    tick_marks = np.arange(len(cls))\n",
    "    plt.grid(False)\n",
    "    plt.xticks(tick_marks, cls, rotation=45)\n",
    "    plt.yticks(tick_marks, cls)\n",
    "    \n",
    "    for i in range(len(cls)):\n",
    "        for j in range(len(cls)):\n",
    "            plt.text(j - 0.2, i, str(conf_mat[i][j]), fontsize=16)\n",
    "    \n",
    "    if file_name:\n",
    "        plt.savefig(file_name)\n",
    "    plt.show()\n",
    "\n",
    "def class_distribution_hist(y_true, y_pred, cls, x_label, y_label, title, file_name=None):\n",
    "    pd.Series([y_true, y_pred]).hist()\n",
    "    plt.title(title)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel(x_label)\n",
    "    tick_marks = np.arange(len(cls))\n",
    "    plt.xticks(tick_marks, cls)\n",
    "    plt.legend(labels=['Real', 'Predicted'], loc='best')\n",
    "    \n",
    "    if file_name:\n",
    "        plt.savefig(file_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['no hate', 'hate speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots([history.history['categorical_accuracy'],\n",
    "       history.history['val_categorical_accuracy'],\n",
    "       model.mc.val_f1s0,\n",
    "       model.mc.val_f1s1],\n",
    "      ['training acc.', 'validation acc.', 'no-hate f1 score', 'hate-speech f1 score'],\n",
    "      ['-r', '--r', 'b', 'm'],\n",
    "      title='Training progress', file_name='results/en_conv/train_progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twinx_plot(history.history['categorical_accuracy'], history.history['val_categorical_accuracy'],\n",
    "           history.history['loss'], history.history['val_loss'],\n",
    "          x_label='Epoch', y1_label='Accuracy', y2_label='Loss', title='Accuracy & loss / epoch',\n",
    "          file_name='results/en_conv/acc_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_plot(conf_mat, cls=classes,\n",
    "                      x_label='Real', y_label='Predicted',\n",
    "                      title='Accuracy: {}'.format(round(acc, 2)),\n",
    "                      file_name='results/en_conv/cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_distribution_hist(y_true, y_pred, cls=classes,\n",
    "                        x_label='Classes', y_label='Cardinality', title='Real and pred. classes cards.',\n",
    "                        file_name='results/en_conv/cards.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hsd/DavidsonEtAl/perfect_data.pkl', 'rb') as f:\n",
    "    texts, _ = pickle.load(f)\n",
    "texts = texts[int(SPLIT_RATIO*len(texts)):]\n",
    "\n",
    "indices = [6, 10, 19, 26, 27, 28, 29, 164]\n",
    "test_cases = []\n",
    "for i, (t, p, l) in enumerate(zip(texts, y_pred, y_true)):\n",
    "    if i in indices:\n",
    "        test_cases.append({'Text': t, 'Prediction': p.numpy(), 'Label': l.numpy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cases_board(test_cases, title, file_name=None):\n",
    "    h = 20\n",
    "    n = len(test_cases)\n",
    "    fig, axis = plt.subplots(1, 1, figsize=(16., n*3.2))\n",
    "    axis.axis('off')\n",
    "    axis.set_xlim([0, 100])\n",
    "    axis.set_ylim([0, n*h])\n",
    "    axis.plot([0, 100], [0, 0], color='k')\n",
    "    axis.plot([0, 0], [0, n*h], color='k')\n",
    "    axis.plot([100, 100], [0, n*h], color='k')\n",
    "    \n",
    "    for i in range(n):\n",
    "        axis.annotate('Tweet text:', xy=(4, 16 + i*h),\n",
    "                      xycoords='data', size=15, fontweight='bold')\n",
    "        text = u'{}'.format(test_cases[i]['Text'].replace('\\n', ''))\n",
    "        text = '\\n'.join([text[j:j+int(len(text)/3)] for j in range(0, len(text), int(len(text)/3))])\n",
    "        axis.annotate(text, xy=(4, 7 + i*h), xycoords='data', size=15)\n",
    "        \n",
    "        axis.annotate('Prediction:', xy=(4, 4 + i*h),\n",
    "                      xycoords='data', size=15, fontweight='bold')\n",
    "        pred = 'no hate' if test_cases[i]['Prediction'] == 0 else 'hate speech'\n",
    "        pred_color = 'b' if pred == 'no hate' else 'm'\n",
    "        axis.annotate(pred, xy=(15, 4 + i*h), xycoords='data', size=15, color=pred_color)\n",
    "        \n",
    "        axis.annotate('Label:', xy=(27, 4 + i*h),\n",
    "                      xycoords='data', size=15, fontweight='bold')\n",
    "        label = 'no hate' if test_cases[i]['Label'] == 0 else 'hate speech'\n",
    "        label_color = 'b' if label == 'no hate' else 'm'\n",
    "        axis.annotate(label, xy=(34, 4 + i*h), xycoords='data', size=15, color=label_color)\n",
    "        \n",
    "        axis.annotate('Result:', xy=(50, 4 + i*h),\n",
    "                      xycoords='data', size=15, fontweight='bold')\n",
    "        reason = 'OK' if pred == label else '1-st type error' if pred == 'no hate' else '2-nd type error'\n",
    "        reason_color = 'g' if reason == 'OK' else 'r'\n",
    "        axis.annotate(reason, xy=(57, 4 + i*h), xycoords='data', size=15, color=reason_color)\n",
    "        \n",
    "        axis.plot([0, 100], [20 + i*h, 20 + i*h], color='k')\n",
    "    \n",
    "    \n",
    "    plt.title(title)\n",
    "    if file_name:\n",
    "        plt.savefig(file_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_cases_board(test_cases, title='Tweets summary', file_name='results/en_conv/tweets_summary.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hate Speech Detector - EN - Convolutional model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test features, predict classes, assign tweets and save to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('tests/en_conv/assigned_labels.csv', 'w') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow(['Label'])\n",
    "    \n",
    "#     t = tqdm(sorted(glob.glob('tests/en_conv/X*')))\n",
    "#     for file_name in t:\n",
    "#         t.set_postfix_str(file_name)\n",
    "#         archive = dir_archive(file_name, {}, cached=True)\n",
    "#         archive.load()\n",
    "\n",
    "#         test_features = archive['features']\n",
    "#         sh = test_features.shape\n",
    "#         test_features =  test_features.reshape(sh[0], sh[1], sh[2]/3, 3)\n",
    "        \n",
    "#         test_predictions = model.predict(test_features)\n",
    "#         test_labels = tf.argmax(test_predictions, axis=1).numpy()\n",
    "        \n",
    "#         for tl in test_labels:\n",
    "#             writer.writerow([tl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
