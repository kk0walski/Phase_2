{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hate Speech Detector - EN - Features extraction for SVM & Dense model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [this notebook](https://github.com/t-davidson/hate-speech-and-offensive-language/blob/master/classifier/final_classifier.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "from klepto.archives import dir_archive\n",
    "import sys\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import fasttext\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VS\n",
    "import syllables as sylla\n",
    "from pymagnitude import *\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'dense'\n",
    "dim = 10 if MODEL == 'svm' else 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Davidson et al. data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes pre:\n",
    "    0 - hate speech\n",
    "    1 - offensive language\n",
    "    2 - neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('hsd/Reddit/perfect_data.pkl'):\n",
    "    tweets, labels = [], []\n",
    "    with open('hsd/Reddit/labeled_data.csv', 'r') as f:\n",
    "        for d in tqdm(list(csv.reader(f))[1:]):\n",
    "            tweets.append(d[6])  # tweet\n",
    "            labels.append(d[5])  # class\n",
    "    with open('hsd/Reddit/perfect_data.pkl', 'w') as f:\n",
    "        def chcl(c):\n",
    "            return 0 if c=='0' else 1\n",
    "        labels = list(map(chcl, labels))\n",
    "        pickle.dump((tweets, labels), f)\n",
    "else:\n",
    "    with open('hsd/Reddit/perfect_data.pkl', 'rb') as f:\n",
    "        tweets, labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes post:\n",
    "    0 - no hate\n",
    "    1 - hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tweets: 55132\nLabels: 55132\n"
     ]
    }
   ],
   "source": [
    "print('Tweets: {}'.format(len(tweets)))\n",
    "print('Labels: {}'.format(len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(\"i joined gab to remind myself how retarded jew haters are. You wouldn't be typing on your abacus without them you retard.\",\n",
       "  1),\n",
       " ('This is what the left is really scared of.    https://redd.it/9rfkts', 0),\n",
       " ('That literally looks like a monkey. Why are we supposed to pretend it’s a person bc it’s wearing a red hat?',\n",
       "  0),\n",
       " ('Dumb Cunt', 1),\n",
       " ('It makes you an asshole.', 0)]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "list(zip(tweets[:5], labels[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "other_exclusions = [\"#ff\", \"ff\", \"rt\"]\n",
    "stopwords.extend(other_exclusions)\n",
    "\n",
    "sentiment_analyzer = VS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_preprocess(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    #hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, '', parsed_text)\n",
    "    #parsed_text = re.sub(hashtag_regex, '', parsed_text)\n",
    "    return parsed_text\n",
    "\n",
    "def pos_tagger(nltk_tag): \n",
    "    if nltk_tag.startswith('J'): \n",
    "        return wordnet.ADJ \n",
    "    elif nltk_tag.startswith('V'): \n",
    "        return wordnet.VERB \n",
    "    elif nltk_tag.startswith('N'): \n",
    "        return wordnet.NOUN \n",
    "    elif nltk_tag.startswith('R'): \n",
    "        return wordnet.ADV \n",
    "    else:           \n",
    "        return None\n",
    "\n",
    "def word_tokenization(tweet):\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    tokens = word_tokenize(tweet)\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    # stop_words = set(stopwords.words('english'))\n",
    "    # words = [w for w in words if not w in stop_words]\n",
    "    tags = nltk.pos_tag(words)\n",
    "    # words = [lemmatizer.lemmatize(w[0]) if pos_tagger(w[1]) is None else lemmatizer.lemmatize(w[0], pos_tagger(w[1])) for w in tags]\n",
    "    tags = [x[1] for x in tags]\n",
    "    return words, tags\n",
    "\n",
    "def preprocess(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = text_string.encode('ascii', 'ignore').decode('ascii')\n",
    "    parsed_text = re.sub(space_pattern, ' ', parsed_text)\n",
    "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, '', parsed_text)\n",
    "    parsed_text = parsed_text.strip('#')\n",
    "    list_words, tag_list = word_tokenization(parsed_text)\n",
    "    parsed_text = \" \".join(list_words)\n",
    "    tag_str = ' '.join(tag_list)\n",
    "    return parsed_text, tag_str\n",
    "\n",
    "def basic_tokenize(tweet):\n",
    "    tweet = \" \".join(re.split(\" \", tweet.lower())).strip()\n",
    "    return tweet.split()\n",
    "\n",
    "# def get_pos_string(tweet):\n",
    "#     text = preprocess(tweet)\n",
    "#     tokens = word_tokenize(text)\n",
    "#     tags = nltk.pos_tag(tokens)\n",
    "#     tag_list = [x[1] for x in tags]\n",
    "#     tag_str = ' '.join(tag_list)\n",
    "    \n",
    "    # return tag_str\n",
    "\n",
    "def pad_words(words, length):\n",
    "    if len(words) >= length:\n",
    "        return words[:length]\n",
    "    else:\n",
    "        additional = length - len(words)\n",
    "        return words + ['EMPTY']*additional\n",
    "\n",
    "def count_twitter_objs(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned.\n",
    "    \n",
    "    Returns counts of urls, mentions, and hashtags.\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "\n",
    "def other_features(tweet):\n",
    "    \"\"\"This function takes a string and returns a list of features.\n",
    "    These include Sentiment scores, Text and Readability scores,\n",
    "    as well as Twitter specific features\"\"\"\n",
    "    sentiment = sentiment_analyzer.polarity_scores(tweet)\n",
    "    \n",
    "    words = preprocess(tweet)[0] #Get text only\n",
    "    \n",
    "    syllables = sylla.estimate(words)\n",
    "    num_chars = sum(len(w) for w in words)\n",
    "    num_chars_total = len(tweet)\n",
    "    num_terms = len(tweet.split())\n",
    "    num_words = len(words.split())\n",
    "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "    num_unique_terms = len(set(words.split()))\n",
    "    \n",
    "    ###Modified FK grade, where avg words per sentence is just num words/1\n",
    "    FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59, 1)\n",
    "    ##Modified FRE score, where sentence fixed to 1\n",
    "    FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)), 2)\n",
    "    \n",
    "    twitter_objs = count_twitter_objs(tweet)\n",
    "    retweet = 0 if \"rt\" in words else 1\n",
    "    features = [FKRA, FRE, syllables, avg_syl, num_chars, num_chars_total, num_terms, num_words,\n",
    "                num_unique_terms, sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound'],\n",
    "                twitter_objs[2], twitter_objs[1],\n",
    "                twitter_objs[0], retweet]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised fastText wordtokens training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('hsd/Reddit/fasttext.ft'):\n",
    "    with open('hsd/Reddit/fasttext.ft', 'a') as f:\n",
    "        for t, l in list(zip(tweets, labels)):\n",
    "            text = preprocess(t)[0]\n",
    "            if len(text) > 0:\n",
    "                f.write('__label__{} {}\\n'.format(l, text))\n",
    "\n",
    "# load fasttext model or train & save if none\n",
    "if os.path.exists('hsd/Reddit/fasttext_{}.bin'.format(MODEL)):\n",
    "    ft_model = fasttext.load_model('hsd/Reddit/fasttext_{}.bin'.format(MODEL))\n",
    "else:\n",
    "    ft_model = fasttext.train_supervised('hsd/Reddit/fasttext.ft',\n",
    "                                         lr=0.5, epoch=50, wordNgrams=3, dim=dim)\n",
    "    ft_model.save_model('hsd/Reddit/fasttext_{}.bin'.format(MODEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordtoken features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordtoken_fts(data):\n",
    "    \n",
    "    sentences_words = []\n",
    "    for d in data:\n",
    "        sentence = preprocess(d)[0]\n",
    "        sentences_words.append(sentence.split(' '))\n",
    "    \n",
    "    opt_length = int(np.median([len(sw) for sw in sentences_words]))\n",
    "    sentences_words = [pad_words(sw, opt_length) for sw in sentences_words]\n",
    "    \n",
    "    ft_vectors = []\n",
    "    for sw in sentences_words:\n",
    "        ft_vector = []\n",
    "        for w in sw:\n",
    "            ft_vector.extend(ft_model[w])\n",
    "        ft_vectors.append(ft_vector)\n",
    "    \n",
    "    return ft_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordtoken_features = get_wordtoken_fts(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-0.020074433,\n",
       " -0.0010464381,\n",
       " 0.024866536,\n",
       " -0.022601176,\n",
       " -0.0059229187,\n",
       " 0.04829487,\n",
       " 0.10509797,\n",
       " 0.056436967,\n",
       " -0.13000314,\n",
       " -0.023368329,\n",
       " 0.05507625,\n",
       " 0.050443072,\n",
       " -0.015017701,\n",
       " -0.020066796,\n",
       " -0.026433446,\n",
       " -0.025757207,\n",
       " -0.007738385,\n",
       " 0.044283252,\n",
       " 0.027462238,\n",
       " -0.049093556,\n",
       " 0.021676162,\n",
       " 0.040927622,\n",
       " 0.029724373,\n",
       " 0.017214471,\n",
       " -0.022925016,\n",
       " -0.0058470326,\n",
       " -0.04114398,\n",
       " 0.05169604,\n",
       " 0.062522255,\n",
       " -0.04631921,\n",
       " -0.0050944826,\n",
       " -0.081099875,\n",
       " 0.033975657,\n",
       " -0.01625956,\n",
       " 0.04779283,\n",
       " 0.0018938238,\n",
       " 0.043410126,\n",
       " -0.029346984,\n",
       " -0.018147536,\n",
       " -0.008108199,\n",
       " -0.003423023,\n",
       " -0.05781455,\n",
       " -0.06602539,\n",
       " -0.0012340905,\n",
       " -0.0057204165,\n",
       " -0.024898654,\n",
       " -0.03922726,\n",
       " -0.06900807,\n",
       " -0.061060507,\n",
       " -0.026512388,\n",
       " -0.00084784144,\n",
       " -0.031567097,\n",
       " -0.019074213,\n",
       " 0.010728149,\n",
       " 0.035440855,\n",
       " 0.025398087,\n",
       " 0.014900015,\n",
       " 0.0728808,\n",
       " 0.022989659,\n",
       " -0.052744262,\n",
       " -0.08789888,\n",
       " -0.04611443,\n",
       " -0.040348634,\n",
       " -0.08190622,\n",
       " 0.032269992,\n",
       " -0.10168228,\n",
       " 0.026007347,\n",
       " -0.028958278,\n",
       " 0.01420271,\n",
       " 0.01709969,\n",
       " -0.03800972,\n",
       " -0.045087263,\n",
       " -0.049269713,\n",
       " 0.042162046,\n",
       " 0.09436826,\n",
       " 0.009204253,\n",
       " -0.094205916,\n",
       " 0.05717653,\n",
       " -0.07678897,\n",
       " 0.016474247,\n",
       " -0.026406936,\n",
       " 0.0149787,\n",
       " 0.06503322,\n",
       " 0.042937703,\n",
       " 0.03388138,\n",
       " 0.020371635,\n",
       " -0.028200233,\n",
       " -0.032496978,\n",
       " 0.039785765,\n",
       " 0.000121234785,\n",
       " 0.037598725,\n",
       " 0.00069326843,\n",
       " -0.039996803,\n",
       " -0.0021545189,\n",
       " -0.034011766,\n",
       " 0.05464955,\n",
       " 0.0063955095,\n",
       " -0.02729815,\n",
       " -0.014877416,\n",
       " -0.06349506,\n",
       " 0.056190673,\n",
       " -0.038345836,\n",
       " 0.060619004,\n",
       " -0.040797617,\n",
       " -0.03405337,\n",
       " -0.094531275,\n",
       " 0.044789635,\n",
       " 0.026804673,\n",
       " -0.035941396,\n",
       " -0.03244033,\n",
       " 0.052124318,\n",
       " -0.07707922,\n",
       " 0.06729627,\n",
       " -0.015908549,\n",
       " -0.05819101,\n",
       " -0.015728861,\n",
       " -0.0010500698,\n",
       " 0.06581024,\n",
       " -0.009285391,\n",
       " 0.102569595,\n",
       " -0.10618673,\n",
       " -0.069432095,\n",
       " -0.028671019,\n",
       " -0.017726066,\n",
       " 0.060343355,\n",
       " -0.052630547,\n",
       " -0.052265678,\n",
       " 0.04562366,\n",
       " 0.039061137,\n",
       " 0.055361524,\n",
       " -0.014935253,\n",
       " -0.059344273,\n",
       " 0.03749929,\n",
       " -0.077493906,\n",
       " -0.01098652,\n",
       " 0.0053826566,\n",
       " -0.030191658,\n",
       " -0.031743594,\n",
       " 0.040985048,\n",
       " -0.01470715,\n",
       " -0.0013200779,\n",
       " -0.02103485,\n",
       " 0.04795553,\n",
       " -0.0005402239,\n",
       " -0.03595098,\n",
       " -0.034816395,\n",
       " -0.012434865,\n",
       " 0.047938544,\n",
       " -0.021726597,\n",
       " -0.0016203466,\n",
       " 0.04903142,\n",
       " 0.033622928,\n",
       " 0.019252636,\n",
       " 0.019500894,\n",
       " 0.022759367,\n",
       " 0.020969123,\n",
       " 0.028352346,\n",
       " -0.0029131277,\n",
       " -0.046534237,\n",
       " -0.061505657,\n",
       " 0.12753294,\n",
       " -0.0029206679,\n",
       " 0.055159785,\n",
       " 0.0062578656,\n",
       " 0.045569755,\n",
       " 0.036982875,\n",
       " -0.023548407,\n",
       " 0.024802312,\n",
       " -0.00017841434,\n",
       " 0.025405522,\n",
       " -0.016898448,\n",
       " 0.03747486,\n",
       " -0.0063181752,\n",
       " 0.0034089596,\n",
       " -0.002096134,\n",
       " -0.06017551,\n",
       " -0.009097363,\n",
       " -0.12591177,\n",
       " -0.020834342,\n",
       " -0.030272003,\n",
       " -0.08857001,\n",
       " -0.011290545,\n",
       " -0.053135596,\n",
       " -0.04199832,\n",
       " -0.06859911,\n",
       " -0.033266116,\n",
       " -0.0015611375,\n",
       " -0.020063333,\n",
       " 0.08030441,\n",
       " 0.06785136,\n",
       " -0.019811232,\n",
       " -0.023388844,\n",
       " 0.034072254,\n",
       " -0.01633366,\n",
       " -0.016340885,\n",
       " 0.06505057,\n",
       " -0.0036801074,\n",
       " -0.029353397,\n",
       " 0.048572972,\n",
       " 0.016597813,\n",
       " 0.009120959,\n",
       " -0.0036785372,\n",
       " -0.013253811,\n",
       " 0.011386667,\n",
       " 0.0019811697,\n",
       " -0.02259983,\n",
       " -0.043802876,\n",
       " -0.019587066,\n",
       " 0.056527548,\n",
       " 0.01821579,\n",
       " -0.024832383,\n",
       " -0.022890802,\n",
       " 0.0069697895,\n",
       " 0.007149034,\n",
       " 0.016331844,\n",
       " 0.013454239,\n",
       " 0.0056995437,\n",
       " -0.024460046,\n",
       " -0.0091370195,\n",
       " 0.02580584,\n",
       " -0.0047626267,\n",
       " -0.019184975,\n",
       " -0.010549537,\n",
       " -0.0024083157,\n",
       " 0.006704123,\n",
       " 0.0031104768,\n",
       " 0.014301289,\n",
       " -0.026062148,\n",
       " -0.031284034,\n",
       " 0.022763524,\n",
       " -0.001376694,\n",
       " 0.040093426,\n",
       " -0.011509869,\n",
       " 0.011239936,\n",
       " -0.02445599,\n",
       " -0.0021783449,\n",
       " -0.018336793,\n",
       " 0.012861939,\n",
       " 0.006977805,\n",
       " 0.007699476,\n",
       " 0.0057455846,\n",
       " 0.030665189,\n",
       " 0.034848485,\n",
       " -0.003759778,\n",
       " 0.0037467924,\n",
       " 0.014389451,\n",
       " 0.020289082,\n",
       " 0.031230666,\n",
       " 0.02479264,\n",
       " 0.014296607,\n",
       " 0.0011969924,\n",
       " 0.017450565,\n",
       " 0.0052497527,\n",
       " -0.002142788,\n",
       " -0.01689601,\n",
       " -0.013691613,\n",
       " -0.0016410758,\n",
       " -0.03130093,\n",
       " -0.017712558,\n",
       " 0.028730432,\n",
       " 0.043463532,\n",
       " 0.02439852,\n",
       " 0.017657699,\n",
       " 0.031595495,\n",
       " -0.015172609,\n",
       " 0.047428582,\n",
       " -0.015164463,\n",
       " 0.013614562,\n",
       " -0.0035317545,\n",
       " -0.013479169,\n",
       " 0.020622792,\n",
       " 0.014411569,\n",
       " 0.017970987,\n",
       " -0.020172236,\n",
       " -0.04206664,\n",
       " -0.010349837,\n",
       " 0.051432423,\n",
       " -0.027043568,\n",
       " 0.04120067,\n",
       " -0.0051056235,\n",
       " 0.017703284,\n",
       " -0.0022983085,\n",
       " -0.031941336,\n",
       " -0.013437044,\n",
       " -0.012105761,\n",
       " -0.0033700296,\n",
       " 0.014218855,\n",
       " 0.017364677,\n",
       " -0.017770877,\n",
       " -0.0021239438,\n",
       " -0.013213671,\n",
       " 0.0048089228,\n",
       " 0.01648298,\n",
       " -0.003988899,\n",
       " 0.010858581,\n",
       " -0.027430147,\n",
       " -0.0038597188,\n",
       " 0.015226342,\n",
       " 0.005128533,\n",
       " 0.03383154,\n",
       " -0.02248541,\n",
       " 0.025610162,\n",
       " -0.028005138,\n",
       " 0.01580447,\n",
       " 0.009258091,\n",
       " 0.041137937,\n",
       " -0.01989934,\n",
       " -0.012744052,\n",
       " 0.014680447,\n",
       " 0.01141227,\n",
       " -0.027015023,\n",
       " 0.036754876,\n",
       " -0.023766425,\n",
       " 0.004257939,\n",
       " 0.028418534,\n",
       " 0.011701578,\n",
       " -0.008153513,\n",
       " -0.027311277,\n",
       " 0.0006250326,\n",
       " -0.046069913,\n",
       " 0.04698878,\n",
       " 0.028888626,\n",
       " 0.016373387,\n",
       " 0.0044264854,\n",
       " -0.025108922,\n",
       " 0.028916044,\n",
       " 0.016077353,\n",
       " -0.018826349,\n",
       " -0.01952574,\n",
       " -0.022330232,\n",
       " 0.010861575,\n",
       " 0.026959578,\n",
       " -0.018630698,\n",
       " 0.041692242,\n",
       " 0.008834769,\n",
       " -0.0022555501,\n",
       " 0.0118984375,\n",
       " 0.018421587,\n",
       " -0.018659143,\n",
       " 0.0062090815,\n",
       " 0.0013933055,\n",
       " 0.00498779,\n",
       " -0.02123261,\n",
       " 0.0052498654,\n",
       " 0.017938217,\n",
       " 0.012499839,\n",
       " 0.011369543,\n",
       " -0.023930877,\n",
       " 0.011459566,\n",
       " -0.0037659016,\n",
       " -0.020410128,\n",
       " -0.014931232,\n",
       " -0.0034278114,\n",
       " -0.006155987,\n",
       " -0.014227056,\n",
       " -0.0039423914,\n",
       " -0.018370828,\n",
       " 0.002559483,\n",
       " 0.02114456,\n",
       " 0.025901001,\n",
       " -0.060992304,\n",
       " 0.010641129,\n",
       " -0.022070896,\n",
       " 0.0033672703,\n",
       " -0.022233082,\n",
       " -0.022075733,\n",
       " 0.010785388,\n",
       " -0.010117084,\n",
       " 0.005577564,\n",
       " -0.0038670027,\n",
       " 0.009165628,\n",
       " -0.017369326,\n",
       " 0.010876171,\n",
       " -0.005499853,\n",
       " -0.0031207933,\n",
       " 0.02553404,\n",
       " 0.0059799016,\n",
       " 0.061603762,\n",
       " 0.014067286,\n",
       " 0.015383797,\n",
       " 0.040832385,\n",
       " 0.0038540447,\n",
       " 0.024620028,\n",
       " 0.019249134,\n",
       " 0.028107168,\n",
       " 0.014791062,\n",
       " 0.0042450093,\n",
       " 0.0033830667,\n",
       " -0.03357813,\n",
       " -0.02839053,\n",
       " 0.016097924,\n",
       " 0.0093143275,\n",
       " -0.011856222,\n",
       " 0.011333345,\n",
       " 0.0058624283,\n",
       " -0.030184003,\n",
       " 0.0044394787,\n",
       " 0.009746279,\n",
       " -0.025852252,\n",
       " -0.009715178,\n",
       " 0.039969902,\n",
       " -0.012014847,\n",
       " -0.06697296,\n",
       " 0.035139743,\n",
       " 0.022608493,\n",
       " -0.09413085,\n",
       " -0.19965005,\n",
       " -0.10695485,\n",
       " 0.27322796,\n",
       " 0.058281712,\n",
       " -0.11472651,\n",
       " -0.115969196,\n",
       " 0.04671583,\n",
       " 0.033036,\n",
       " 0.061398063,\n",
       " 0.05926586,\n",
       " 0.016364168,\n",
       " -0.102337316,\n",
       " -0.043854322,\n",
       " 0.10090859,\n",
       " -0.04820585,\n",
       " -0.103310205,\n",
       " -0.06248201,\n",
       " -0.029793767,\n",
       " 0.045600507,\n",
       " 0.01951967,\n",
       " 0.08433083,\n",
       " -0.11556723,\n",
       " -0.13787642,\n",
       " 0.089734614,\n",
       " 0.01843993,\n",
       " 0.16783826,\n",
       " -0.077208616,\n",
       " 0.039754096,\n",
       " -0.09727464,\n",
       " -0.021420961,\n",
       " -0.10327373,\n",
       " 0.075322665,\n",
       " 0.02881835,\n",
       " 0.023340715,\n",
       " 0.008012886,\n",
       " 0.14215988,\n",
       " 0.15866752,\n",
       " 0.0051084836,\n",
       " 0.028242053,\n",
       " 0.049272038,\n",
       " 0.09446329,\n",
       " 0.14680432,\n",
       " 0.1205006,\n",
       " 0.06395093,\n",
       " 0.020111935,\n",
       " 0.06228995,\n",
       " 0.036290947,\n",
       " -0.020772086,\n",
       " -0.068070985,\n",
       " -0.06601357,\n",
       " -0.017064605,\n",
       " -0.15624376,\n",
       " -0.06741109,\n",
       " 0.112346865,\n",
       " 0.19725685,\n",
       " 0.10065474,\n",
       " 0.0903262,\n",
       " 0.16920705,\n",
       " -0.069630414,\n",
       " 0.2138076,\n",
       " -0.061523583,\n",
       " 0.08095205,\n",
       " -0.01943574,\n",
       " -0.040191863,\n",
       " 0.08645269,\n",
       " 0.09294363,\n",
       " 0.097220935,\n",
       " -0.085659005,\n",
       " -0.19559844,\n",
       " -0.040608916,\n",
       " 0.22478522,\n",
       " -0.13182326,\n",
       " 0.19310728,\n",
       " -0.033880077,\n",
       " 0.0717731,\n",
       " -0.032858137,\n",
       " -0.14877655,\n",
       " -0.069666,\n",
       " -0.06954057,\n",
       " -0.03622338,\n",
       " 0.060846224,\n",
       " 0.07531921,\n",
       " -0.08599434,\n",
       " -0.010189936,\n",
       " -0.06508886,\n",
       " 0.009731152,\n",
       " 0.08154942,\n",
       " -0.002590821,\n",
       " 0.070407666,\n",
       " -0.12277626,\n",
       " -0.014045415,\n",
       " 0.059958067,\n",
       " 0.040925402,\n",
       " 0.15396145,\n",
       " -0.117988326,\n",
       " 0.10038478,\n",
       " -0.1268543,\n",
       " 0.07367885,\n",
       " 0.06693766,\n",
       " 0.20928875,\n",
       " -0.0959918,\n",
       " -0.05641512,\n",
       " 0.0808537,\n",
       " 0.0637387,\n",
       " -0.117480114,\n",
       " 0.1499388,\n",
       " -0.1208612,\n",
       " 0.023217991,\n",
       " 0.118471034,\n",
       " 0.046371974,\n",
       " -0.014400497,\n",
       " -0.13263313,\n",
       " 0.020831939,\n",
       " -0.22356567,\n",
       " 0.21988815,\n",
       " 0.138214,\n",
       " 0.06096159,\n",
       " 0.044385374,\n",
       " -0.11719531,\n",
       " 0.12139023,\n",
       " 0.102975845,\n",
       " -0.103220955,\n",
       " -0.08607162,\n",
       " -0.108988464,\n",
       " 0.027081227,\n",
       " 0.12055893,\n",
       " -0.08264007,\n",
       " 0.17652063,\n",
       " 0.02733199,\n",
       " -0.013816657,\n",
       " 0.06589169,\n",
       " 0.073564455,\n",
       " -0.09825446,\n",
       " 0.03607181,\n",
       " 0.010899792,\n",
       " 0.04414957,\n",
       " -0.10663884,\n",
       " 0.005013345,\n",
       " 0.086472906,\n",
       " 0.06546946,\n",
       " 0.033593,\n",
       " -0.09725051,\n",
       " 0.057773974,\n",
       " -0.0032923794,\n",
       " -0.092003986,\n",
       " -0.05854623,\n",
       " -0.0355139,\n",
       " -0.040240552,\n",
       " -0.0525478,\n",
       " -0.040508777,\n",
       " -0.06030228,\n",
       " 0.0065667527,\n",
       " 0.10001798,\n",
       " 0.12176088,\n",
       " -0.2629676,\n",
       " 0.022630952,\n",
       " -0.12955698,\n",
       " -0.008434322,\n",
       " -0.09486351,\n",
       " -0.078867145,\n",
       " 0.04734009,\n",
       " -0.058278784,\n",
       " -0.0017572884,\n",
       " -0.040731795,\n",
       " 0.026714403,\n",
       " -0.088560164,\n",
       " 0.023310293,\n",
       " -0.011285664,\n",
       " -0.01044205,\n",
       " 0.11854286,\n",
       " 0.030854052,\n",
       " 0.26908863,\n",
       " 0.057349365,\n",
       " 0.06844387,\n",
       " 0.17342868,\n",
       " 0.030035852,\n",
       " 0.10565885,\n",
       " 0.09297428,\n",
       " 0.15229471,\n",
       " 0.074053034,\n",
       " 0.008823317,\n",
       " 0.031197755,\n",
       " -0.15530375,\n",
       " -0.14226136,\n",
       " 0.05198962,\n",
       " 0.056502167,\n",
       " -0.08047908,\n",
       " 0.0267537,\n",
       " 0.020637011,\n",
       " -0.1328036,\n",
       " 0.006224827,\n",
       " 0.047378935,\n",
       " -0.09735966,\n",
       " -0.023991013,\n",
       " 0.02492885,\n",
       " -0.0024136968,\n",
       " -0.040530648,\n",
       " 0.021430787,\n",
       " 0.0141537115,\n",
       " -0.06395078,\n",
       " -0.12520479,\n",
       " -0.06353878,\n",
       " 0.16168055,\n",
       " 0.03887462,\n",
       " -0.055992186,\n",
       " -0.06352259,\n",
       " 0.006519009,\n",
       " 0.00935718,\n",
       " 0.021555657,\n",
       " 0.024073023,\n",
       " 0.007184216,\n",
       " -0.030851217,\n",
       " -0.019815117,\n",
       " 0.047704548,\n",
       " -0.01770519,\n",
       " -0.0363737,\n",
       " -0.023162413,\n",
       " -0.0082861325,\n",
       " 0.02207617,\n",
       " 0.015581834,\n",
       " 0.036250714,\n",
       " -0.06024881,\n",
       " -0.08859713,\n",
       " 0.058038954,\n",
       " 0.011804698,\n",
       " 0.09846127,\n",
       " -0.049940143,\n",
       " 0.019085538,\n",
       " -0.06359026,\n",
       " -0.005773074,\n",
       " -0.077543266,\n",
       " 0.055887796,\n",
       " 0.022627186,\n",
       " 0.020622024,\n",
       " 0.0028913177,\n",
       " 0.089260906,\n",
       " 0.10458177,\n",
       " 0.009498439,\n",
       " 0.010223159,\n",
       " 0.020625673,\n",
       " 0.042699445,\n",
       " 0.079346485,\n",
       " 0.06379277,\n",
       " 0.02979492,\n",
       " 0.0037029914,\n",
       " 0.046443835,\n",
       " 0.024154073,\n",
       " -0.012536076,\n",
       " -0.037609566,\n",
       " -0.025967956,\n",
       " -0.015914064,\n",
       " -0.086263046,\n",
       " -0.041911937,\n",
       " 0.077030055,\n",
       " 0.111609004,\n",
       " 0.057456646,\n",
       " 0.043072518,\n",
       " 0.08162221,\n",
       " -0.03183505,\n",
       " 0.111012004,\n",
       " -0.03818287,\n",
       " 0.04603642,\n",
       " -0.014268332,\n",
       " -0.017829223,\n",
       " 0.04237436,\n",
       " 0.05903095,\n",
       " 0.052951682,\n",
       " -0.05524275,\n",
       " -0.12758067,\n",
       " -0.022999868,\n",
       " 0.12819709,\n",
       " -0.074130714,\n",
       " 0.10293164,\n",
       " -0.015695821,\n",
       " 0.03752954,\n",
       " -0.02017181,\n",
       " -0.092713855,\n",
       " -0.04594626,\n",
       " -0.035854317,\n",
       " -0.019390335,\n",
       " 0.034203697,\n",
       " 0.041344248,\n",
       " -0.04694789,\n",
       " -0.0019232327,\n",
       " -0.03838828,\n",
       " 0.004418831,\n",
       " 0.048056405,\n",
       " 0.0028031932,\n",
       " 0.03615434,\n",
       " -0.062818125,\n",
       " -0.0091751795,\n",
       " 0.03365195,\n",
       " 0.012095964,\n",
       " 0.07562638,\n",
       " -0.06907713,\n",
       " 0.054722544,\n",
       " -0.06802339,\n",
       " 0.051846795,\n",
       " 0.045403514,\n",
       " 0.13115543,\n",
       " -0.055678006,\n",
       " -0.033924744,\n",
       " 0.038171615,\n",
       " 0.03814399,\n",
       " -0.06609003,\n",
       " 0.08899969,\n",
       " -0.06780524,\n",
       " 0.0121788755,\n",
       " 0.0730492,\n",
       " 0.025519073,\n",
       " -0.004846218,\n",
       " -0.072414905,\n",
       " 0.015565516,\n",
       " -0.12436889,\n",
       " 0.11636818,\n",
       " 0.071279146,\n",
       " 0.04075614,\n",
       " 0.02103555,\n",
       " -0.046971783,\n",
       " 0.050414156,\n",
       " 0.0403124,\n",
       " -0.043951947,\n",
       " -0.0460927,\n",
       " -0.055376362,\n",
       " 0.009867393,\n",
       " 0.06282555,\n",
       " -0.047811266,\n",
       " 0.111612216,\n",
       " 0.021128252,\n",
       " -0.0054107015,\n",
       " 0.041717984,\n",
       " 0.045216754,\n",
       " -0.06955225,\n",
       " 0.022564324,\n",
       " 0.010714188,\n",
       " 0.025761614,\n",
       " -0.06752507,\n",
       " -0.0007776056,\n",
       " 0.056693215,\n",
       " 0.036520813,\n",
       " 0.018907577,\n",
       " -0.06496936,\n",
       " 0.034824383,\n",
       " -0.0027210193,\n",
       " -0.06822376,\n",
       " -0.038927805,\n",
       " -0.032815047,\n",
       " -0.02304253,\n",
       " -0.033107504,\n",
       " -0.02275496,\n",
       " -0.034485947,\n",
       " 0.0035573225,\n",
       " 0.06724432,\n",
       " 0.07947316,\n",
       " -0.16983363,\n",
       " 0.0143757695,\n",
       " -0.08759979,\n",
       " -0.012392391,\n",
       " -0.071229465,\n",
       " -0.061260127,\n",
       " 0.028248532,\n",
       " -0.04772813,\n",
       " -0.0065102205,\n",
       " -0.029535787,\n",
       " 0.022765504,\n",
       " -0.05838049,\n",
       " 0.019171342,\n",
       " -0.0076414407,\n",
       " -0.005957193,\n",
       " 0.0781114,\n",
       " 0.022433352,\n",
       " 0.1892429,\n",
       " 0.041053057,\n",
       " 0.049451947,\n",
       " 0.1360629,\n",
       " 0.024327857,\n",
       " 0.0999123,\n",
       " 0.08284781,\n",
       " 0.13639544,\n",
       " 0.05336362,\n",
       " -0.00041014177,\n",
       " 0.026966387,\n",
       " -0.112383775,\n",
       " -0.08706937,\n",
       " 0.032328032,\n",
       " 0.035318516,\n",
       " -0.060180426,\n",
       " 0.021370258,\n",
       " 0.016978636,\n",
       " -0.08449389,\n",
       " 0.0025794248,\n",
       " 0.030375408,\n",
       " -0.064188965,\n",
       " -0.019616636,\n",
       " 0.024680056,\n",
       " -0.0013310572,\n",
       " -0.03450793,\n",
       " 0.023299698,\n",
       " 0.008911215,\n",
       " -0.054394696,\n",
       " -0.117758796,\n",
       " -0.06529771,\n",
       " 0.15216476,\n",
       " 0.035034988,\n",
       " -0.072138466,\n",
       " -0.06374622,\n",
       " 0.02879719,\n",
       " 0.024713017,\n",
       " 0.03085959,\n",
       " 0.028888939,\n",
       " 0.01211718,\n",
       " -0.05748736,\n",
       " -0.02831295,\n",
       " 0.06330691,\n",
       " -0.030177532,\n",
       " -0.062894255,\n",
       " -0.03711107,\n",
       " -0.015410426,\n",
       " 0.023576682,\n",
       " 0.007883699,\n",
       " 0.043698166,\n",
       " -0.06829818,\n",
       " -0.07486888,\n",
       " 0.048235733,\n",
       " 0.012913698,\n",
       " 0.0932859,\n",
       " -0.046080437,\n",
       " 0.02416742,\n",
       " -0.05511355,\n",
       " -0.009378158,\n",
       " -0.06258602,\n",
       " 0.040290706,\n",
       " 0.010241235,\n",
       " 0.010233626,\n",
       " -0.0004612997,\n",
       " 0.07592899,\n",
       " 0.091038816,\n",
       " 0.004316048,\n",
       " 0.018551733,\n",
       " 0.021565804,\n",
       " 0.05177542,\n",
       " 0.08064788,\n",
       " 0.074497744,\n",
       " 0.039735436,\n",
       " 0.012416931,\n",
       " 0.040772714,\n",
       " 0.016916161,\n",
       " -0.011364127,\n",
       " -0.03955815,\n",
       " -0.03459759,\n",
       " -0.0124743255,\n",
       " -0.08805373,\n",
       " -0.037855648,\n",
       " 0.062656485,\n",
       " 0.11181021,\n",
       " 0.059499223,\n",
       " 0.052191556,\n",
       " 0.10051153,\n",
       " -0.03762288,\n",
       " 0.11996154,\n",
       " -0.03610032,\n",
       " 0.04231489,\n",
       " -0.013513357,\n",
       " -0.021683881,\n",
       " 0.048985798,\n",
       " 0.047993712,\n",
       " 0.056717277,\n",
       " -0.052122746,\n",
       " -0.113172226,\n",
       " -0.020597529,\n",
       " 0.13062227,\n",
       " -0.07301343,\n",
       " 0.106476925,\n",
       " -0.021347843,\n",
       " 0.03836279,\n",
       " -0.021321185,\n",
       " -0.08630884,\n",
       " -0.042984243,\n",
       " -0.038484592,\n",
       " -0.023741126,\n",
       " 0.030257659,\n",
       " 0.04254608,\n",
       " -0.047066838,\n",
       " -0.0057547996,\n",
       " -0.03750688,\n",
       " 0.0037047032,\n",
       " 0.04763157,\n",
       " 0.00024391022,\n",
       " 0.03583801,\n",
       " -0.06225436,\n",
       " -0.007446443,\n",
       " 0.036396783,\n",
       " 0.02024884,\n",
       " 0.08721294,\n",
       " -0.071929775,\n",
       " 0.058824357,\n",
       " -0.07566425,\n",
       " 0.041859675,\n",
       " 0.035206623,\n",
       " 0.120088056,\n",
       " -0.056461032,\n",
       " -0.03022884,\n",
       " 0.04388844,\n",
       " 0.034743626,\n",
       " -0.064671464,\n",
       " 0.08142325,\n",
       " -0.07198838,\n",
       " 0.0137271825,\n",
       " 0.066390164,\n",
       " 0.027656494,\n",
       " -0.0075973133,\n",
       " -0.07823891,\n",
       " 0.010418344,\n",
       " -0.12977307,\n",
       " 0.121537715,\n",
       " 0.07632126,\n",
       " 0.03807691,\n",
       " 0.02672455,\n",
       " -0.067118526,\n",
       " 0.06642611,\n",
       " 0.05122892,\n",
       " -0.061509617,\n",
       " -0.05179258,\n",
       " -0.055402108,\n",
       " 0.014142879,\n",
       " 0.063157134,\n",
       " -0.048368484,\n",
       " 0.10035706,\n",
       " 0.015412105,\n",
       " -0.0035438188,\n",
       " 0.035554424,\n",
       " 0.04188935,\n",
       " -0.05929977,\n",
       " 0.024234008,\n",
       " 0.0077258507,\n",
       " 0.01924602,\n",
       " -0.056093674,\n",
       " -0.0033797396,\n",
       " 0.044415273,\n",
       " 0.04200412,\n",
       " 0.022547392,\n",
       " -0.058507223,\n",
       " 0.03533303,\n",
       " -0.006812253,\n",
       " -0.053085294,\n",
       " -0.03318852,\n",
       " -0.021678397,\n",
       " -0.021781541,\n",
       " -0.027409483,\n",
       " -0.026532965,\n",
       " -0.037223376,\n",
       " 0.0009708395,\n",
       " 0.060197383,\n",
       " 0.072570525,\n",
       " -0.14556503,\n",
       " 0.014361496,\n",
       " -0.070409656,\n",
       " -0.0024439907,\n",
       " -0.0548961,\n",
       " -0.05073843,\n",
       " 0.023976427,\n",
       " -0.035281133,\n",
       " 0.0030917523,\n",
       " -0.023695406,\n",
       " 0.012937867,\n",
       " -0.04946761,\n",
       " 0.010715022,\n",
       " -0.008505021,\n",
       " -0.00403965,\n",
       " 0.061765492,\n",
       " 0.019127045,\n",
       " 0.15246391,\n",
       " 0.03227281,\n",
       " 0.036596347,\n",
       " 0.10175216,\n",
       " 0.015359999,\n",
       " 0.05947698,\n",
       " 0.047466584,\n",
       " 0.08604919,\n",
       " 0.038253803,\n",
       " 0.0045212633,\n",
       " 0.01512154,\n",
       " -0.092548154,\n",
       " -0.07625422,\n",
       " 0.027088637,\n",
       " 0.03391172,\n",
       " -0.044246167,\n",
       " 0.019347746,\n",
       " 0.01650214,\n",
       " -0.07517071,\n",
       " 0.0012507761,\n",
       " 0.02670859,\n",
       " -0.055661004,\n",
       " -0.017243445,\n",
       " ...]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "wordtoken_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised fastText pos training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('hsd/Reddit/fasttext_pos.ft'):\n",
    "    with open('hsd/Reddit/fasttext_pos.ft', 'a') as f:\n",
    "        for t, l in list(zip(tweets, labels)):\n",
    "            f.write('__label__{} {}\\n'.format(l, preprocess(t)[1]))\n",
    "\n",
    "# load fasttext pos model or train & save if none\n",
    "if os.path.exists('hsd/Reddit/fasttext_pos_{}.bin'.format(MODEL)):\n",
    "    ft_pos_model = fasttext.load_model('hsd/Reddit/fasttext_pos_{}.bin'.format(MODEL))\n",
    "else:\n",
    "    ft_pos_model = fasttext.train_supervised('hsd/Reddit/fasttext_pos.ft',\n",
    "                                             lr=0.5, epoch=50, wordNgrams=3, dim=dim)\n",
    "    ft_pos_model.save_model('hsd/Reddit/fasttext_pos_{}.bin'.format(MODEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of speech (PoS) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_fts(data):\n",
    "\n",
    "    #Get POS tags for tweets and save as a string\n",
    "    pos_sentences = []\n",
    "    for d in data:\n",
    "        pos_string = preprocess(d)[1]\n",
    "        pos_sentences.append(pos_string)\n",
    "        \n",
    "        \n",
    "    pos_tags = []\n",
    "    for ps in pos_sentences:\n",
    "        pos_tags.append(ps.split(' '))\n",
    "    \n",
    "    opt_length = int(np.median([len(pt) for pt in pos_tags]))\n",
    "    pos_tags = [pad_words(pt, opt_length) for pt in pos_tags]\n",
    "    \n",
    "    ft_vectors = []\n",
    "    for pt in pos_tags:\n",
    "        ft_vector = []\n",
    "        for t in pt:\n",
    "            ft_vector.extend(ft_pos_model[t])\n",
    "        ft_vectors.append(ft_vector)\n",
    "    \n",
    "    return ft_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features = get_pos_fts(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-0.24737507,\n",
       " 0.37265313,\n",
       " -0.10580574,\n",
       " -0.6254099,\n",
       " -0.68918836,\n",
       " 0.23592462,\n",
       " -0.3190713,\n",
       " -0.14368151,\n",
       " 0.6848899,\n",
       " 1.6542645,\n",
       " 0.0017685906,\n",
       " -1.0936574,\n",
       " -1.149242,\n",
       " -0.24874505,\n",
       " 0.43608025,\n",
       " 0.39674857,\n",
       " 0.36702904,\n",
       " 0.0762877,\n",
       " -0.007873814,\n",
       " 0.887947,\n",
       " -0.24737507,\n",
       " 0.37265313,\n",
       " -0.10580574,\n",
       " -0.6254099,\n",
       " -0.68918836,\n",
       " 0.23592462,\n",
       " -0.3190713,\n",
       " -0.14368151,\n",
       " 0.6848899,\n",
       " 1.6542645,\n",
       " 0.09965002,\n",
       " 1.1912097,\n",
       " 1.4800516,\n",
       " 1.148172,\n",
       " -0.93075204,\n",
       " -1.0350236,\n",
       " -0.95710313,\n",
       " -0.5307445,\n",
       " -0.245457,\n",
       " -1.5423375,\n",
       " -0.18846865,\n",
       " -0.12492545,\n",
       " -0.69818294,\n",
       " 0.6093615,\n",
       " -0.19825664,\n",
       " 0.07976622,\n",
       " -0.04633593,\n",
       " 0.2905052,\n",
       " 0.26071504,\n",
       " 0.84542716,\n",
       " 0.2638475,\n",
       " 0.017239993,\n",
       " 0.28201565,\n",
       " 0.4577914,\n",
       " -0.20165063,\n",
       " 0.057426896,\n",
       " -0.09905324,\n",
       " -0.2408881,\n",
       " 0.6813042,\n",
       " -0.49243268,\n",
       " 0.5184322,\n",
       " 0.7475772,\n",
       " 1.2300949,\n",
       " -0.28866297,\n",
       " -0.3084485,\n",
       " 0.53250855,\n",
       " -0.65286666,\n",
       " -0.3846743,\n",
       " -0.027212892,\n",
       " -1.6446086,\n",
       " -0.18099292,\n",
       " -0.11273867,\n",
       " -0.5382735,\n",
       " 0.22672129,\n",
       " 0.15421152,\n",
       " -0.5887575,\n",
       " 0.009247217,\n",
       " -0.21273844,\n",
       " -0.07030978,\n",
       " -0.17093872,\n",
       " -0.24737507,\n",
       " 0.37265313,\n",
       " -0.10580574,\n",
       " -0.6254099,\n",
       " -0.68918836,\n",
       " 0.23592462,\n",
       " -0.3190713,\n",
       " -0.14368151,\n",
       " 0.6848899,\n",
       " 1.6542645,\n",
       " 0.1044839,\n",
       " 0.1731615,\n",
       " -0.37339273,\n",
       " -0.4748119,\n",
       " -0.043588955,\n",
       " -0.601536,\n",
       " -0.09269765,\n",
       " -0.5678071,\n",
       " 0.09377726,\n",
       " -0.5495178,\n",
       " 0.5839329,\n",
       " 0.4049192,\n",
       " -0.06278053,\n",
       " 1.05945,\n",
       " -0.008029658,\n",
       " -0.2181972,\n",
       " -0.44797146,\n",
       " 0.71487933,\n",
       " -0.1575744,\n",
       " -0.23846829,\n",
       " 0.2638475,\n",
       " 0.017239993,\n",
       " 0.28201565,\n",
       " 0.4577914,\n",
       " -0.20165063,\n",
       " 0.057426896,\n",
       " -0.09905324,\n",
       " -0.2408881,\n",
       " 0.6813042,\n",
       " -0.49243268,\n",
       " 0.42994145,\n",
       " 0.715326,\n",
       " 1.942948,\n",
       " 0.9638929,\n",
       " -1.4921291,\n",
       " -0.672632,\n",
       " -0.9012448,\n",
       " 0.35361004,\n",
       " -0.6773979,\n",
       " -1.3417462,\n",
       " -0.18846865,\n",
       " -0.12492545,\n",
       " -0.69818294,\n",
       " 0.6093615,\n",
       " -0.19825664,\n",
       " 0.07976622,\n",
       " -0.04633593,\n",
       " 0.2905052,\n",
       " 0.26071504,\n",
       " 0.84542716,\n",
       " 0.7289296,\n",
       " 0.09864499,\n",
       " -0.13250026,\n",
       " -0.1531917,\n",
       " 0.20306085,\n",
       " -0.6191224,\n",
       " -0.6912209,\n",
       " 0.67886126,\n",
       " -0.42236543,\n",
       " 0.38569188,\n",
       " -0.081076115,\n",
       " 0.5468184,\n",
       " 1.1953201,\n",
       " 1.3184576,\n",
       " -0.46320418,\n",
       " -0.58106834,\n",
       " 0.30815455,\n",
       " -0.04126657,\n",
       " -0.45021698,\n",
       " -0.26580834,\n",
       " 0.0040883403,\n",
       " 0.8313247,\n",
       " 1.3094866,\n",
       " 0.26576495,\n",
       " -0.74674827,\n",
       " -0.2768435,\n",
       " -0.124513365,\n",
       " -0.38683245,\n",
       " -0.43678617,\n",
       " -1.0281967,\n",
       " -0.24737507,\n",
       " 0.37265313,\n",
       " -0.10580574,\n",
       " -0.6254099,\n",
       " -0.68918836,\n",
       " 0.23592462,\n",
       " -0.3190713,\n",
       " -0.14368151,\n",
       " 0.6848899,\n",
       " 1.6542645,\n",
       " -0.081076115,\n",
       " 0.5468184,\n",
       " 1.1953201,\n",
       " 1.3184576,\n",
       " -0.46320418,\n",
       " -0.58106834,\n",
       " 0.30815455,\n",
       " -0.04126657,\n",
       " -0.45021698,\n",
       " -0.26580834]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "pos_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features = np.array([other_features(t) for t in tweets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1.1200e+01,  5.3760e+01,  3.4000e+01,  1.5454e+00,  1.2100e+02,\n",
       "         1.2100e+02,  2.2000e+01,  2.2000e+01,  2.2000e+01,  2.4100e-01,\n",
       "         9.7000e-02,  6.6300e-01, -6.2780e-01,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  1.0000e+00],\n",
       "       [ 2.3000e+00,  9.4300e+01,  1.1000e+01,  1.2222e+00,  4.3000e+01,\n",
       "         6.8000e+01,  1.0000e+01,  9.0000e+00,  8.0000e+00,  2.6200e-01,\n",
       "         0.0000e+00,  7.3800e-01, -4.9270e-01,  0.0000e+00,  0.0000e+00,\n",
       "         1.0000e+00,  1.0000e+00],\n",
       "       [ 1.0000e+01,  6.0630e+01,  3.1000e+01,  1.4762e+00,  1.0700e+02,\n",
       "         1.0700e+02,  2.1000e+01,  2.1000e+01,  1.8000e+01,  6.1000e-02,\n",
       "         1.0900e-01,  8.3000e-01,  2.7320e-01,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  1.0000e+00],\n",
       "       [-3.0000e+00,  1.2021e+02,  2.0000e+00,  1.0000e+00,  9.0000e+00,\n",
       "         9.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,  1.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00, -7.5790e-01,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  1.0000e+00],\n",
       "       [ 2.9000e+00,  8.3330e+01,  7.0000e+00,  1.3999e+00,  2.4000e+01,\n",
       "         2.4000e+01,  5.0000e+00,  5.0000e+00,  5.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  1.0000e+00]])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "other_features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(55132, 190)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "np.array(wordtoken_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(55132, 190)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "np.array(pos_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(55132, 17)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "np.array(other_features).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All features and feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now join them all up\n",
    "features = np.concatenate([wordtoken_features, pos_features, other_features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(55132, 397)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = dir_archive('hsd/Reddit/X_y_{}'.format(MODEL), {'features': features, 'labels': labels}, serialized=True)\n",
    "archive.dump()\n",
    "del archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}